// EmbeddingUtils.js
const { get_encoding } = require("@dqbd/tiktoken");
const encoding = get_encoding("cl100k_base");

// é…ç½®
const embeddingMaxToken = parseInt(process.env.WhitelistEmbeddingModelMaxToken, 10) || 8000;
const safeMaxTokens = Math.floor(embeddingMaxToken * 0.85);
const MAX_BATCH_ITEMS = 100; // Gemini/OpenAI é™åˆ¶
const DEFAULT_CONCURRENCY = parseInt(process.env.TAG_VECTORIZE_CONCURRENCY) || 5; // ğŸŒŸ è¯»å–å¹¶å‘é…ç½®

/**
 * å†…éƒ¨å‡½æ•°ï¼šå‘é€å•ä¸ªæ‰¹æ¬¡
 */
async function _sendBatch(batchTexts, config, batchNumber) {
    const { default: fetch } = await import('node-fetch');
    const retryAttempts = 3;
    const baseDelay = 1000;

    for (let attempt = 1; attempt <= retryAttempts; attempt++) {
        try {
            const requestUrl = `${config.apiUrl}/v1/embeddings`;
            const requestBody = { model: config.model, input: batchTexts };
            const requestHeaders = { 'Content-Type': 'application/json', 'Authorization': `Bearer ${config.apiKey}` };

            const response = await fetch(requestUrl, {
                method: 'POST',
                headers: requestHeaders,
                body: JSON.stringify(requestBody)
            });

            const responseBodyText = await response.text();

            if (!response.ok) {
                if (response.status === 429) {
                    // 429 é™æµæ—¶ï¼Œå¢åŠ ç­‰å¾…æ—¶é—´
                    const waitTime = 5000 * attempt;
                    console.warn(`[Embedding] Batch ${batchNumber} rate limited (429). Retrying in ${waitTime / 1000}s...`);
                    await new Promise(r => setTimeout(r, waitTime));
                    continue;
                }
                throw new Error(`API Error ${response.status}: ${responseBodyText.substring(0, 500)}`);
            }

            let data;
            try {
                data = JSON.parse(responseBodyText);
            } catch (parseError) {
                console.error(`[Embedding] JSON Parse Error for Batch ${batchNumber}:`);
                console.error(`Response (first 500 chars): ${responseBodyText.substring(0, 500)}`);
                throw new Error(`Failed to parse API response as JSON: ${parseError.message}`);
            }

            // å¢å¼ºçš„å“åº”ç»“æ„éªŒè¯å’Œè¯¦ç»†é”™è¯¯ä¿¡æ¯
            if (!data) {
                throw new Error(`API returned empty/null response`);
            }

            // æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯å“åº”
            if (data.error) {
                const errorMsg = data.error.message || JSON.stringify(data.error);
                const errorCode = data.error.code || response.status;
                console.error(`[Embedding] API Error for Batch ${batchNumber}:`);
                console.error(`  Error Code: ${errorCode}`);
                console.error(`  Error Message: ${errorMsg}`);
                console.error(`  Hint: Check if embedding model "${config.model}" is available on your API server`);
                throw new Error(`API Error ${errorCode}: ${errorMsg}`);
            }

            if (!data.data) {
                console.error(`[Embedding] Missing 'data' field in response for Batch ${batchNumber}`);
                console.error(`Response keys: ${Object.keys(data).join(', ')}`);
                console.error(`Response preview: ${JSON.stringify(data).substring(0, 500)}`);
                throw new Error(`Invalid API response structure: missing 'data' field`);
            }

            if (!Array.isArray(data.data)) {
                console.error(`[Embedding] 'data' field is not an array for Batch ${batchNumber}`);
                console.error(`data type: ${typeof data.data}`);
                console.error(`data value: ${JSON.stringify(data.data).substring(0, 200)}`);
                throw new Error(`Invalid API response structure: 'data' is not an array`);
            }

            if (data.data.length === 0) {
                console.warn(`[Embedding] Warning: Batch ${batchNumber} returned empty embeddings array`);
            }

            // ç®€å•çš„ Logï¼Œè¯æ˜å¹¶å‘æ­£åœ¨è·‘
            // console.log(`[Embedding] âœ… Batch ${batchNumber} completed (${batchTexts.length} items).`);

            return data.data.sort((a, b) => a.index - b.index).map(item => item.embedding);

        } catch (e) {
            console.warn(`[Embedding] Batch ${batchNumber}, Attempt ${attempt} failed: ${e.message}`);
            if (attempt === retryAttempts) throw e;
            await new Promise(r => setTimeout(r, baseDelay * Math.pow(2, attempt)));
        }
    }
}

/**
 * ğŸš€ ç»ˆæç‰ˆï¼šå¹¶å‘æ‰¹é‡è·å– Embeddings
 * ğŸ›¡ï¸ æ ¸å¿ƒä¿è¯ï¼šè¿”å›æ•°ç»„é•¿åº¦ === è¾“å…¥ texts é•¿åº¦ï¼Œè·³è¿‡/å¤±è´¥çš„ä½ç½®å¡« null
 */
async function getEmbeddingsBatch(texts, config) {
    if (!texts || texts.length === 0) return [];

    // 1. âš¡ï¸ ç¬¬ä¸€æ­¥ï¼šçº¯ CPU æ“ä½œï¼Œå…ˆæŠŠæ‰€æœ‰æ–‡æœ¬åˆ‡åˆ†æˆ Batches
    //    åŒæ—¶è®°å½•æ¯ä¸ªæ–‡æœ¬åœ¨åŸå§‹æ•°ç»„ä¸­çš„ç´¢å¼•ï¼Œä»¥ä¾¿åç»­å¯¹é½
    const batches = [];         // æ¯ä¸ªå…ƒç´ : { texts: string[], originalIndices: number[] }
    let currentBatchTexts = [];
    let currentBatchIndices = [];
    let currentBatchTokens = 0;
    const oversizeIndices = new Set(); // è®°å½•è¢«è·³è¿‡çš„è¶…é•¿æ–‡æœ¬ä½ç½®

    for (let i = 0; i < texts.length; i++) {
        const text = texts[i];
        const textTokens = encoding.encode(text).length;
        if (textTokens > safeMaxTokens) {
            console.warn(`[Embedding] âš ï¸ Text at index ${i} exceeds token limit (${textTokens} > ${safeMaxTokens}), skipping.`);
            oversizeIndices.add(i);
            continue; // Skip oversizeï¼Œä½†è®°å½•ä½ç½®
        }

        const isTokenFull = currentBatchTexts.length > 0 && (currentBatchTokens + textTokens > safeMaxTokens);
        const isItemFull = currentBatchTexts.length >= MAX_BATCH_ITEMS;

        if (isTokenFull || isItemFull) {
            batches.push({ texts: currentBatchTexts, originalIndices: currentBatchIndices });
            currentBatchTexts = [text];
            currentBatchIndices = [i];
            currentBatchTokens = textTokens;
        } else {
            currentBatchTexts.push(text);
            currentBatchIndices.push(i);
            currentBatchTokens += textTokens;
        }
    }
    if (currentBatchTexts.length > 0) {
        batches.push({ texts: currentBatchTexts, originalIndices: currentBatchIndices });
    }

    if (oversizeIndices.size > 0) {
        console.warn(`[Embedding] âš ï¸ ${oversizeIndices.size} texts skipped due to token limit.`);
    }
    console.log(`[Embedding] Prepared ${batches.length} batches from ${texts.length} texts. Executing with concurrency: ${DEFAULT_CONCURRENCY}...`);

    // 2. ğŸŒŠ ç¬¬äºŒæ­¥ï¼šå¹¶å‘æ‰§è¡Œå™¨
    const batchResults = new Array(batches.length); // é¢„åˆ†é…ç»“æœæ•°ç»„ï¼Œä¿è¯é¡ºåº
    let cursor = 0; // å½“å‰å¤„ç†åˆ°çš„æ‰¹æ¬¡ç´¢å¼•

    // å®šä¹‰ Workerï¼šåªè¦é˜Ÿåˆ—é‡Œè¿˜æœ‰ä»»åŠ¡ï¼Œå°±ä¸æ–­æŠ¢ä»»åŠ¡åš
    const worker = async (workerId) => {
        while (true) {
            // ğŸ”’ è·å–ä»»åŠ¡ç´¢å¼• (åŸå­æ“ä½œæ¨¡æ‹Ÿ)
            const batchIndex = cursor++;
            if (batchIndex >= batches.length) break; // æ²¡ä»»åŠ¡äº†ï¼Œä¸‹ç­

            const batch = batches[batchIndex];
            try {
                // æ‰§è¡Œè¯·æ±‚ (Batch ID ä» 1 å¼€å§‹æ˜¾ç¤º)
                batchResults[batchIndex] = {
                    vectors: await _sendBatch(batch.texts, config, batchIndex + 1),
                    originalIndices: batch.originalIndices
                };
            } catch (e) {
                // ğŸ›¡ï¸ ä¸å†è®©å•ä¸ª batch å¤±è´¥å¯¼è‡´æ•´ä¸ª Promise.all å´©æºƒ
                // è€Œæ˜¯è®°å½•å¤±è´¥ï¼Œå¯¹åº”ä½ç½®å°†å¡« null
                console.error(`[Embedding] âŒ Batch ${batchIndex + 1} failed permanently: ${e.message}`);
                batchResults[batchIndex] = {
                    vectors: null, // æ ‡è®°ä¸ºå¤±è´¥
                    originalIndices: batch.originalIndices,
                    error: e.message
                };
            }
        }
    };

    // å¯åŠ¨ N ä¸ª Worker
    const workers = [];
    for (let i = 0; i < DEFAULT_CONCURRENCY; i++) {
        workers.push(worker(i));
    }

    // ç­‰å¾…æ‰€æœ‰ Worker ä¸‹ç­
    await Promise.all(workers);

    // 3. ğŸ“¦ ç¬¬ä¸‰æ­¥ï¼šæŒ‰åŸå§‹ç´¢å¼•å›å¡«ç»“æœï¼Œä¿è¯ output.length === input.length
    const finalResults = new Array(texts.length).fill(null); // é»˜è®¤å…¨éƒ¨ä¸º null
    let successCount = 0;
    let failCount = 0;

    for (const result of batchResults) {
        if (!result || !result.vectors) {
            // æ•´ä¸ª batch å¤±è´¥ï¼Œå¯¹åº”ä½ç½®ä¿æŒ null
            if (result) failCount += result.originalIndices.length;
            continue;
        }
        result.originalIndices.forEach((origIdx, vecIdx) => {
            finalResults[origIdx] = result.vectors[vecIdx] || null;
            if (result.vectors[vecIdx]) successCount++;
            else failCount++;
        });
    }

    failCount += oversizeIndices.size; // è¶…é•¿æ–‡æœ¬ä¹Ÿç®—å¤±è´¥

    if (failCount > 0) {
        console.warn(`[Embedding] âš ï¸ Results: ${successCount} succeeded, ${failCount} failed/skipped out of ${texts.length} total.`);
    }

    return finalResults; // ğŸ›¡ï¸ é•¿åº¦ä¸¥æ ¼ç­‰äº texts.lengthï¼Œå¤±è´¥ä½ç½®ä¸º null
}

module.exports = { getEmbeddingsBatch };